{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "81-gUJRUQ5k-"
      },
      "source": [
        "**Authors**\n",
        "\n",
        "Umberto Altieri - umberto.altieri@studio.unibo.it \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfgaHq7bSsDd"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spHgvShShJfR",
        "outputId": "7f5f22e2-4034-4b80-cf06-962335814371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "from nltk.stem import \tWordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
        "import pickle\n",
        "from transformers import *\n",
        "from tqdm import tqdm, trange\n",
        "from ast import literal_eval\n",
        "import urllib.request\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import copy\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNnosSRJSwin"
      },
      "source": [
        "#The GPU used is Tesla T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMnLrz3ahroV",
        "outputId": "6e5907cf-9998-4f4f-bdb2-c08e37154975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dkXWVD2KhuKR",
        "outputId": "c5c51e50-860a-4d84-bb4a-16472b2b6024"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE_IbbudS3Ty"
      },
      "source": [
        "#Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eB__Dof29jGu"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "set_reproducibility(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRfzIxOZh1Dy"
      },
      "source": [
        "#Import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB7j-1FOZNBh"
      },
      "source": [
        "The data are downloaded by the links provided by the challenge website. On the  [website](https://zenodo.org/record/7503506) are provided: 1 dataset for the training, 2 for the validation and 1 for the test set. Unfortunately this last one is without labels, as the evaluation of the performance on the test dataset is provided through the website tira, where the labels produced by the model should be uploaded to know the performances of the problem, that will be evaluated at the end of the challenge.\n",
        "It is for this reason that the model will be evaluated on one of the two validation dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ca21VHF3V3o"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.tsv')\n",
        "  \n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading dataset {suffix} ... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HLsMmtIh3Zi"
      },
      "outputs": [],
      "source": [
        "# Train data examples\n",
        "train_url = \"https://zenodo.org/record/7402070/files/arguments-training.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url, suffix='train_examples')\n",
        "\n",
        "# Train data labels\n",
        "train_url = \"https://zenodo.org/record/7402070/files/labels-training.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url, suffix='train_labels')\n",
        "\n",
        "# Validation data examples\n",
        "train_url = \"https://zenodo.org/record/7402070/files/arguments-validation.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url, suffix='validation_examples')\n",
        "\n",
        "# Validation data labels\n",
        "train_url = \"https://zenodo.org/record/7402070/files/labels-validation.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url, suffix='validation_labels')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://zenodo.org/record/7402070/files/arguments-test.tsv?download=1\"\n",
        "download_data(data_path='data', url_path=test_url, suffix='test') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tpfrm5RivNK"
      },
      "outputs": [],
      "source": [
        "# Train data arguments\n",
        "train_url_arguments = \"https://zenodo.org/record/7402070/files/arguments-training.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url_arguments, suffix='train_arguments')\n",
        "# Train data labels\n",
        "train_url_labels = \"https://zenodo.org/record/7402070/files/labels-training.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = train_url_labels, suffix='train_labels')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Validation data arguments\n",
        "val_url_arguments = \"https://zenodo.org/record/7402070/files/arguments-validation.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = val_url_arguments, suffix='validation_arguments')\n",
        "# Validation data labels\n",
        "val_url_labels = \"https://zenodo.org/record/7402070/files/labels-validation.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = val_url_labels, suffix='validation_labels')\n",
        "\n",
        "\n",
        "\n",
        "# Validation data arguments zhihu\n",
        "val_url_arguments_zhihu = \"https://zenodo.org/record/7402070/files/arguments-validation-zhihu.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = val_url_arguments_zhihu, suffix='validation_arguments_zhihu')\n",
        "# Validation data labels zhihu\n",
        "val_url_arguments_zhihu = \"https://zenodo.org/record/7402070/files/labels-validation-zhihu.tsv?download=1\"\n",
        "download_data(data_path='data', url_path = val_url_arguments_zhihu, suffix='validation_labels_zhihu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYTa01-MZW7a"
      },
      "source": [
        "The values in the data are separated by the /t character, as they are .tsv files, loaded as pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-9ZK8YcjQOL"
      },
      "outputs": [],
      "source": [
        "\n",
        "tsv_train_arguments_path='/content/data/train_arguments.tsv'\n",
        "tsv_validation_arguments_path='/content/data/validation_arguments.tsv'\n",
        "tsv_validation_arguments_zhihu_path='/content/data/validation_arguments_zhihu.tsv'\n",
        "\n",
        "\n",
        "\n",
        "tsv_train_labels_path='/content/data/train_labels.tsv'\n",
        "tsv_validation_labels_path='/content/data/validation_labels.tsv'\n",
        "tsv_validation_labels_zhihu_path='/content/data/validation_labels_zhihu.tsv'\n",
        "\n",
        "\n",
        "tsv_train_arguments = pd.read_csv(tsv_train_arguments_path, sep='\\t')\n",
        "tsv_validation_arguments = pd.read_csv(tsv_validation_arguments_path, sep='\\t')\n",
        "tsv_validation_arguments_zhihu = pd.read_csv(tsv_validation_arguments_zhihu_path, sep='\\t')\n",
        "\n",
        "tsv_train_labels = pd.read_csv(tsv_train_labels_path, sep='\\t')\n",
        "tsv_validation_labels = pd.read_csv(tsv_validation_labels_path, sep='\\t')\n",
        "tsv_validation_labels_zhihu = pd.read_csv(tsv_validation_labels_zhihu_path, sep='\\t')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RckofCCLZaps"
      },
      "source": [
        "Creation of the dataframes, the training dataset is merged with the first validation one. While the second validation dataset, called zhihu, is used to test the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7xHlCIzjSeH"
      },
      "outputs": [],
      "source": [
        "df_train= pd.concat([tsv_train_labels,tsv_train_arguments],axis=1)\n",
        "df_val=pd.concat([tsv_validation_labels,tsv_validation_arguments],axis=1)\n",
        "df_val_zhihu=pd.concat([tsv_validation_labels_zhihu,tsv_validation_arguments_zhihu],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhYD2wzNZxac"
      },
      "outputs": [],
      "source": [
        "label_cols = list(df_train.columns[0:-3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njP-t2deULdy",
        "outputId": "f002ef1d-ea4d-411f-a0f1-0310dcbedfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Count of 1 per label: \n",
            " Argument ID                   A01002A01005A01006A01007A01008A01009A01010A010...\n",
            "Argument ID                   A01002A01005A01006A01007A01008A01009A01010A010...\n",
            "Self-direction: thought                                                     988\n",
            "Self-direction: action                                                     1395\n",
            "Stimulation                                                                 247\n",
            "Hedonism                                                                    172\n",
            "Achievement                                                                1512\n",
            "Power: dominance                                                            610\n",
            "Power: resources                                                            625\n",
            "Face                                                                        382\n",
            "Security: personal                                                         2000\n",
            "Security: societal                                                         1728\n",
            "Tradition                                                                   568\n",
            "Conformity: rules                                                          1177\n",
            "Conformity: interpersonal                                                   207\n",
            "Humility                                                                    395\n",
            "Benevolence: caring                                                        1332\n",
            "Benevolence: dependability                                                  806\n",
            "Universalism: concern                                                      2081\n",
            "Universalism: nature                                                        427\n",
            "Universalism: tolerance                                                     664\n",
            "Universalism: objectivity                                                  1054\n",
            "Argument ID                   A01002A01005A01006A01007A01008A01009A01010A010...\n",
            "Argument ID                   A01002A01005A01006A01007A01008A01009A01010A010...\n",
            "dtype: object \n",
            "\n",
            "Train Count of 0 per label: \n",
            " Argument ID                      0\n",
            "Argument ID                      0\n",
            "Self-direction: thought       4405\n",
            "Self-direction: action        3998\n",
            "Stimulation                   5146\n",
            "Hedonism                      5221\n",
            "Achievement                   3881\n",
            "Power: dominance              4783\n",
            "Power: resources              4768\n",
            "Face                          5011\n",
            "Security: personal            3393\n",
            "Security: societal            3665\n",
            "Tradition                     4825\n",
            "Conformity: rules             4216\n",
            "Conformity: interpersonal     5186\n",
            "Humility                      4998\n",
            "Benevolence: caring           4061\n",
            "Benevolence: dependability    4587\n",
            "Universalism: concern         3312\n",
            "Universalism: nature          4966\n",
            "Universalism: tolerance       4729\n",
            "Universalism: objectivity     4339\n",
            "Argument ID                      0\n",
            "Argument ID                      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Train Count of 1 per label: \\n', df_train[label_cols].sum(), '\\n')  \n",
        "print('Train Count of 0 per label: \\n', df_train[label_cols].eq(0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MQmOIGIVX2K",
        "outputId": "e388507d-3e4e-4246-ae3c-ddf24494f2b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5393, 25)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGNtpfr6UPJB",
        "outputId": "a543596e-7b26-4c73-da87-06f39115826c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Count of 1 per label: \n",
            " Argument ID                   C26001C26002C26003C26004C26005C26006C26007C260...\n",
            "Argument ID                   C26001C26002C26003C26004C26005C26006C26007C260...\n",
            "Self-direction: thought                                                       6\n",
            "Self-direction: action                                                       11\n",
            "Stimulation                                                                   0\n",
            "Hedonism                                                                      2\n",
            "Achievement                                                                  39\n",
            "Power: dominance                                                              1\n",
            "Power: resources                                                             19\n",
            "Face                                                                          1\n",
            "Security: personal                                                           30\n",
            "Security: societal                                                           31\n",
            "Tradition                                                                     0\n",
            "Conformity: rules                                                            15\n",
            "Conformity: interpersonal                                                     1\n",
            "Humility                                                                      5\n",
            "Benevolence: caring                                                          12\n",
            "Benevolence: dependability                                                    3\n",
            "Universalism: concern                                                        21\n",
            "Universalism: nature                                                          8\n",
            "Universalism: tolerance                                                       2\n",
            "Universalism: objectivity                                                    26\n",
            "Argument ID                   C26001C26002C26003C26004C26005C26006C26007C260...\n",
            "Argument ID                   C26001C26002C26003C26004C26005C26006C26007C260...\n",
            "dtype: object \n",
            "\n",
            "Validation Count of 0 per label: \n",
            " Argument ID                     0\n",
            "Argument ID                     0\n",
            "Self-direction: thought        94\n",
            "Self-direction: action         89\n",
            "Stimulation                   100\n",
            "Hedonism                       98\n",
            "Achievement                    61\n",
            "Power: dominance               99\n",
            "Power: resources               81\n",
            "Face                           99\n",
            "Security: personal             70\n",
            "Security: societal             69\n",
            "Tradition                     100\n",
            "Conformity: rules              85\n",
            "Conformity: interpersonal      99\n",
            "Humility                       95\n",
            "Benevolence: caring            88\n",
            "Benevolence: dependability     97\n",
            "Universalism: concern          79\n",
            "Universalism: nature           92\n",
            "Universalism: tolerance        98\n",
            "Universalism: objectivity      74\n",
            "Argument ID                     0\n",
            "Argument ID                     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Validation Count of 1 per label: \\n', df_val_zhihu[label_cols].sum(), '\\n')  \n",
        "print('Validation Count of 0 per label: \\n', df_val_zhihu[label_cols].eq(0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo9Z6--_VZy3",
        "outputId": "7e3f9a2c-ab1c-49bc-d97e-00546054fb2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 25)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val_zhihu.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLl3XqBIUOkT",
        "outputId": "3da29ce1-1ef3-40b0-aefd-6e28eb8e4110"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Count of 1 per label: \n",
            " Argument ID                   A01001A01012A02001A02002A02009A02018A03005A030...\n",
            "Argument ID                   A01001A01012A02001A02002A02009A02018A03005A030...\n",
            "Self-direction: thought                                                     251\n",
            "Self-direction: action                                                      496\n",
            "Stimulation                                                                 138\n",
            "Hedonism                                                                    103\n",
            "Achievement                                                                 575\n",
            "Power: dominance                                                            164\n",
            "Power: resources                                                            132\n",
            "Face                                                                        130\n",
            "Security: personal                                                          759\n",
            "Security: societal                                                          488\n",
            "Tradition                                                                   172\n",
            "Conformity: rules                                                           455\n",
            "Conformity: interpersonal                                                    60\n",
            "Humility                                                                    127\n",
            "Benevolence: caring                                                         633\n",
            "Benevolence: dependability                                                  268\n",
            "Universalism: concern                                                       687\n",
            "Universalism: nature                                                        127\n",
            "Universalism: tolerance                                                     223\n",
            "Universalism: objectivity                                                   371\n",
            "Argument ID                   A01001A01012A02001A02002A02009A02018A03005A030...\n",
            "Argument ID                   A01001A01012A02001A02002A02009A02018A03005A030...\n",
            "dtype: object \n",
            "\n",
            "Validation Count of 0 per label: \n",
            " Argument ID                      0\n",
            "Argument ID                      0\n",
            "Self-direction: thought       1645\n",
            "Self-direction: action        1400\n",
            "Stimulation                   1758\n",
            "Hedonism                      1793\n",
            "Achievement                   1321\n",
            "Power: dominance              1732\n",
            "Power: resources              1764\n",
            "Face                          1766\n",
            "Security: personal            1137\n",
            "Security: societal            1408\n",
            "Tradition                     1724\n",
            "Conformity: rules             1441\n",
            "Conformity: interpersonal     1836\n",
            "Humility                      1769\n",
            "Benevolence: caring           1263\n",
            "Benevolence: dependability    1628\n",
            "Universalism: concern         1209\n",
            "Universalism: nature          1769\n",
            "Universalism: tolerance       1673\n",
            "Universalism: objectivity     1525\n",
            "Argument ID                      0\n",
            "Argument ID                      0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Validation Count of 1 per label: \\n', df_val[label_cols].sum(), '\\n')  \n",
        "print('Validation Count of 0 per label: \\n', df_val[label_cols].eq(0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn-uJK-PVbW8",
        "outputId": "27bd6650-59fb-473c-8a31-c5ee27834dc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1896, 25)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLO5s_7HUaTw"
      },
      "source": [
        "It can be seen from the labels count that the dataset of training, validation and validation zhihu keep the same proprotion with respect to their size, but no one of them is balanced, as the difference in number of occurrences between labels is often very large. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F2FNjdiKE6SE"
      },
      "source": [
        "For this reason, as suggested by the Touch√® company I took into account only six labels: Self-direction: action, Achievement, Security: personal, Security: societal, Benevolence: caring, Universalism: concern.\n",
        "Considering only the mentioned classes, the dataset becomes more balanced. In addition, I have added the validation dataset to the training one in order to enlarge the training set, which otherwise would have too few samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95PnPnF7UZ-G"
      },
      "outputs": [],
      "source": [
        "df_train=pd.concat([df_train,df_val],ignore_index=True,axis=0)\n",
        "df_val=df_val_zhihu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Tde876e-FWg"
      },
      "source": [
        "Dropping not needed columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szwARQdFeTQT"
      },
      "outputs": [],
      "source": [
        "del df_train['Argument ID']\n",
        "del df_val['Argument ID']\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WzlyY6Yu-QAe"
      },
      "source": [
        "I narrow down the dataset according to the 6 labels : Self-direction: action, Achievement, Security: personal, Security: societal, Benevolence: caring, Universalism: concern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VB13iHshk5ko"
      },
      "outputs": [],
      "source": [
        "\n",
        "label_cols=['Self-direction: action', 'Achievement', 'Security: personal', 'Security: societal', 'Benevolence: caring', 'Universalism: concern']\n",
        "num_labels=len(label_cols)\n",
        "all_labels=copy.copy(label_cols)\n",
        "all_labels.append('Premise')\n",
        "all_labels.append('Stance')\n",
        "all_labels.append('Conclusion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLdswO-Xf3Zc"
      },
      "outputs": [],
      "source": [
        "df_train=df_train[all_labels]\n",
        "df_val=df_val[all_labels]\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vdObI8WV0_7"
      },
      "source": [
        "Drop the rows in the dataset that do not belong to any of the selected six classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8GabGuv44w5"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.loc[(df_train[label_cols] != 0).any(axis=1)]\n",
        "\n",
        "df_val= df_val.loc[(df_val[label_cols] != 0).any(axis=1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UWqE2ofV_tN"
      },
      "source": [
        "The shape of the 2 datasets shrinks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPLk_UU0SI0H",
        "outputId": "393595e7-843f-4b33-a261-384c76c02b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6753, 9)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA8gVlTwV-4W",
        "outputId": "0e30f23b-a248-4546-ea98-56e8364ededf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(84, 9)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4UyXiZxWQ4i"
      },
      "source": [
        "Shuffling the datasets of training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWRu449dlOES"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.sample(frac=1).reset_index(drop=True) #shuffle rows\n",
        "df_val = df_val.sample(frac=1).reset_index(drop=True) #shuffle rows"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3xadkLLmWV_W"
      },
      "source": [
        "I added one feature that encodes the features of the 6 labels chosen before. It is useful for the training of the model, because summarizes 6 features into only one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "15giyPWplO-e",
        "outputId": "6dea8970-4242-4a5a-f978-4c5cda171314"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6f5b9d80-4f8e-4ff5-aefd-331145b0a9c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Self-direction: action</th>\n",
              "      <th>Achievement</th>\n",
              "      <th>Security: personal</th>\n",
              "      <th>Security: societal</th>\n",
              "      <th>Benevolence: caring</th>\n",
              "      <th>Universalism: concern</th>\n",
              "      <th>Premise</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Conclusion</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Foster children are given a stable home enviro...</td>\n",
              "      <td>against</td>\n",
              "      <td>Foster care brings more harm than good</td>\n",
              "      <td>[0, 0, 1, 0, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>fast food is unhealthy and causes obesity</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>We should ban fast food</td>\n",
              "      <td>[0, 0, 1, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>we need to do away with what there is so there...</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>We should fight for the abolition of nuclear w...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Immigration is a class issue. At the same time...</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>We do not need immigration from non-European o...</td>\n",
              "      <td>[0, 0, 1, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>space exploration is needed to further our nat...</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>We should subsidize space exploration</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f5b9d80-4f8e-4ff5-aefd-331145b0a9c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f5b9d80-4f8e-4ff5-aefd-331145b0a9c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f5b9d80-4f8e-4ff5-aefd-331145b0a9c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Self-direction: action  Achievement  Security: personal  \\\n",
              "0                       0            0                   1   \n",
              "1                       0            0                   1   \n",
              "2                       0            0                   0   \n",
              "3                       0            0                   1   \n",
              "4                       0            1                   0   \n",
              "\n",
              "   Security: societal  Benevolence: caring  Universalism: concern  \\\n",
              "0                   0                    1                      1   \n",
              "1                   1                    0                      0   \n",
              "2                   1                    0                      1   \n",
              "3                   0                    1                      0   \n",
              "4                   1                    0                      0   \n",
              "\n",
              "                                             Premise       Stance  \\\n",
              "0  Foster children are given a stable home enviro...      against   \n",
              "1          fast food is unhealthy and causes obesity  in favor of   \n",
              "2  we need to do away with what there is so there...  in favor of   \n",
              "3  Immigration is a class issue. At the same time...  in favor of   \n",
              "4  space exploration is needed to further our nat...  in favor of   \n",
              "\n",
              "                                          Conclusion      one_hot_labels  \n",
              "0             Foster care brings more harm than good  [0, 0, 1, 0, 1, 1]  \n",
              "1                            We should ban fast food  [0, 0, 1, 1, 0, 0]  \n",
              "2  We should fight for the abolition of nuclear w...  [0, 0, 0, 1, 0, 1]  \n",
              "3  We do not need immigration from non-European o...  [0, 0, 1, 0, 1, 0]  \n",
              "4              We should subsidize space exploration  [0, 1, 0, 1, 0, 0]  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['one_hot_labels'] = list(df_train[label_cols].values)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "PBkQrkC10X96",
        "outputId": "1e19fde8-4a78-4f3b-e26a-d5c903f1a5a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6cffcc5f-1746-4619-a010-72fffd7c312f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Self-direction: action</th>\n",
              "      <th>Achievement</th>\n",
              "      <th>Security: personal</th>\n",
              "      <th>Security: societal</th>\n",
              "      <th>Benevolence: caring</th>\n",
              "      <th>Universalism: concern</th>\n",
              "      <th>Premise</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Conclusion</th>\n",
              "      <th>one_hot_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Putting all the blame on the game, demonizing ...</td>\n",
              "      <td>against</td>\n",
              "      <td>We should restrict minors from playing online ...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Extremely serious information asymmetry. It is...</td>\n",
              "      <td>in favor of</td>\n",
              "      <td>We should protect our privacy in the Internet ...</td>\n",
              "      <td>[1, 0, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The total production is controllable and the v...</td>\n",
              "      <td>against</td>\n",
              "      <td>We should ban the trading of virtual currencies.</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The electric car is driven by an electric moto...</td>\n",
              "      <td>against</td>\n",
              "      <td>We should give up developing electric vehicles</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Monopolies can sometimes protect the public in...</td>\n",
              "      <td>against</td>\n",
              "      <td>We should prohibit capital monopoly.</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6cffcc5f-1746-4619-a010-72fffd7c312f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6cffcc5f-1746-4619-a010-72fffd7c312f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6cffcc5f-1746-4619-a010-72fffd7c312f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Self-direction: action  Achievement  Security: personal  \\\n",
              "0                       0            0                   0   \n",
              "1                       1            0                   1   \n",
              "2                       0            0                   0   \n",
              "3                       0            1                   0   \n",
              "4                       0            1                   0   \n",
              "\n",
              "   Security: societal  Benevolence: caring  Universalism: concern  \\\n",
              "0                   0                    1                      0   \n",
              "1                   0                    0                      0   \n",
              "2                   1                    0                      0   \n",
              "3                   0                    0                      0   \n",
              "4                   1                    0                      0   \n",
              "\n",
              "                                             Premise       Stance  \\\n",
              "0  Putting all the blame on the game, demonizing ...      against   \n",
              "1  Extremely serious information asymmetry. It is...  in favor of   \n",
              "2  The total production is controllable and the v...      against   \n",
              "3  The electric car is driven by an electric moto...      against   \n",
              "4  Monopolies can sometimes protect the public in...      against   \n",
              "\n",
              "                                          Conclusion      one_hot_labels  \n",
              "0  We should restrict minors from playing online ...  [0, 0, 0, 0, 1, 0]  \n",
              "1  We should protect our privacy in the Internet ...  [1, 0, 1, 0, 0, 0]  \n",
              "2   We should ban the trading of virtual currencies.  [0, 0, 0, 1, 0, 0]  \n",
              "3     We should give up developing electric vehicles  [0, 1, 0, 0, 0, 0]  \n",
              "4               We should prohibit capital monopoly.  [0, 1, 0, 1, 0, 0]  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_val['one_hot_labels'] = list(df_val[label_cols].values)\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m1Ea6kjEFHp"
      },
      "source": [
        "Save the labels for the training session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srWcOySx4TrX"
      },
      "outputs": [],
      "source": [
        "labels_train = list(df_train.one_hot_labels.values)\n",
        "labels_val= list(df_val.one_hot_labels.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEElqoaar4V1"
      },
      "source": [
        "#Merging the text arguments as 'Premise'+' '+'Stance'+' '+'Conclusion' to give as input to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exKWNErAr24p"
      },
      "outputs": [],
      "source": [
        "list_text_merged_train=[]\n",
        "for i in range(len(df_train)):\n",
        "   list_text_merged_train.append(df_train['Premise'][i]+' '+df_train['Stance'][i]+' '+df_train['Conclusion'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sikrDPYY1RsR"
      },
      "outputs": [],
      "source": [
        "list_text_merged_val=[]\n",
        "for i in range(len(df_val)):\n",
        "  list_text_merged_val.append(df_val['Premise'][i]+' '+df_val['Stance'][i]+' '+df_val['Conclusion'][i])\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpUlezAJDmNM"
      },
      "source": [
        "Remove punctuation, make the sentences lower case and perform lemmatization. This step standardizes the input, so that the model is not confused by misleading characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oPMdtjkkQBs"
      },
      "outputs": [],
      "source": [
        "def pre_tokenization(list_text_merged):\n",
        "\n",
        "  new_list_text=[]\n",
        "  for sentence in list_text_merged:\n",
        "    new_sentence=sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "    new_sentence=new_sentence.lower()\n",
        "    tokenization = nltk.word_tokenize(new_sentence)\n",
        "    new_sentence_=''\n",
        "    for w in tokenization:\n",
        "      new_sentence_+=wordnet_lemmatizer.lemmatize(w)+' '\n",
        "    new_list_text.append(new_sentence_)\n",
        "  return new_list_text\n",
        "list_text_merged_train=pre_tokenization(list_text_merged_train)\n",
        "list_text_merged_val=pre_tokenization(list_text_merged_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5xTflF73pxN"
      },
      "source": [
        "AVG length of each list of train\\validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O-IG8eh3qQh",
        "outputId": "2795879e-8e32-4ce2-8ca8-dab2db255911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg length of train text:  179.67940174737154\n"
          ]
        }
      ],
      "source": [
        "print('avg length of train text: ' ,sum( map(len, list_text_merged_train) ) / len(list_text_merged_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x8QFMu9ipgz",
        "outputId": "18e42163-1e7c-465c-8cc3-55bb99c28555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg length of train text:  210.17857142857142\n"
          ]
        }
      ],
      "source": [
        "print('avg length of train text: ' ,sum( map(len, list_text_merged_val) ) / len(list_text_merged_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhS-6djXYv0"
      },
      "source": [
        "The max length of the tokenizer is set to 300 in order to deal with memory issue and at the same time avoid truncation of the input sequence, as it is more far greater than the average length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8V6NzTR3nhM",
        "outputId": "a93ef5ad-0fb0-478f-88f7-1c720b80952a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "max_length = 300\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXl5outpX9AC"
      },
      "source": [
        "Performing input Tokenization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZetFYFKhrpLp",
        "outputId": "9a421a48-ad78-4bfe-a95a-90cb33dd97d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2336: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "encodings_train = tokenizer.batch_encode_plus(list_text_merged_train,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
        "encodings_val = tokenizer.batch_encode_plus(list_text_merged_val,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvgCxQj6rHk1"
      },
      "outputs": [],
      "source": [
        "input_ids_train = encodings_train['input_ids'] # tokenized and encoded sentences\n",
        "token_type_ids_train = encodings_train['token_type_ids'] # token type ids\n",
        "attention_masks_train = encodings_train['attention_mask'] # attention masks\n",
        "\n",
        "\n",
        "input_ids_val = encodings_val['input_ids'] # tokenized and encoded sentences\n",
        "token_type_ids_val = encodings_val['token_type_ids'] # token type ids\n",
        "attention_masks_val = encodings_val['attention_mask'] # attention masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-WC0xOenEME"
      },
      "source": [
        "Convert all of our data into torch tensors, the required datatype for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhEtE446iMSV",
        "outputId": "db1e4a04-fbc4-4f61-e00b-f323644e37b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-37-8a6d35bd0b60>:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  train_labels = torch.tensor(train_labels)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_inputs=input_ids_train\n",
        "train_labels=labels_train\n",
        "train_masks=attention_masks_train\n",
        "train_token_types=token_type_ids_train\n",
        "\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "train_token_types = torch.tensor(train_token_types)\n",
        "\n",
        "\n",
        "val_inputs=input_ids_val\n",
        "val_labels=labels_val\n",
        "val_masks=attention_masks_val\n",
        "val_token_types=token_type_ids_val\n",
        "\n",
        "validation_inputs = torch.tensor(val_inputs)\n",
        "validation_labels = torch.tensor(val_labels)\n",
        "validation_masks = torch.tensor(val_masks)\n",
        "validation_token_types = torch.tensor(val_token_types)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Miy_-qGJYOAT"
      },
      "source": [
        "The batch size is set to 32 so that the notebook can run the free version of Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJ2gf8DwiQwx"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory, this will ensure less use of GPU memory.\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nO_iNVZ4iWoi"
      },
      "outputs": [],
      "source": [
        "torch.save(train_dataloader,'train_data_loader')\n",
        "torch.save(validation_dataloader,'validation_data_loader')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ7N4NN_e2Mc"
      },
      "source": [
        "# Load model, and set of parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqar_7LNe5mp",
        "outputId": "18eb9311-3943-462b-b6f5-4dfecedd920f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load model, the pretrained model will include a single linear classification layer on top for classification. \n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLk3vPP_C0Y8"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr7xzVYwfSjh",
        "outputId": "58e24490-7656-408c-e5ea-f4187025f71a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(),lr=2e-5) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NELKrw5oyy3A"
      },
      "source": [
        "#Training of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZF0zIGCGuX"
      },
      "source": [
        "The model is trained for 3 epochs using binary crossentropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HwnyK-WxgpN",
        "outputId": "fa4e103d-2d2f-482d-e542-d428b36bbde8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.5670510779293079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [05:24<05:24, 324.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.4654148698977704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [10:49<00:00, 324.60s/it]\n"
          ]
        }
      ],
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 2\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "  # Training\n",
        "  \n",
        "  # Set our model to training mode (as opposed to evaluation mode)\n",
        "  model.train()\n",
        "\n",
        "  # Tracking variables\n",
        "  tr_loss = 0 #running loss\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # # Forward pass for multiclass classification\n",
        "    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "    # loss = outputs[0]\n",
        "    # logits = outputs[1]\n",
        "\n",
        "    # Forward pass for multilabel classification\n",
        "    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    logits = outputs[0]\n",
        "    loss_func = BCEWithLogitsLoss() \n",
        "    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    # loss_func = BCELoss() \n",
        "    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Variables to gather full output\n",
        "  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n",
        "\n",
        "  # Predict\n",
        "  for i, batch in enumerate(validation_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n",
        "    with torch.no_grad():\n",
        "      # Forward pass\n",
        "      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "      b_logit_pred = outs[0]\n",
        "      pred_label = torch.sigmoid(b_logit_pred)\n",
        "\n",
        "      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n",
        "      pred_label = pred_label.to('cpu').numpy()\n",
        "      b_labels = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tokenized_texts.append(b_input_ids)\n",
        "    logit_preds.append(b_logit_pred)\n",
        "    true_labels.append(b_labels)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "# Flatten outputs\n",
        "pred_labels = [item for sublist in pred_labels for item in sublist]\n",
        "true_labels = [item for sublist in true_labels for item in sublist]\n",
        "# Calculate Accuracy\n",
        "threshold = 0.50\n",
        "pred_bools = [pl>threshold for pl in pred_labels]\n",
        "true_bools = [tl==1 for tl in true_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrFE9B2gysi3",
        "outputId": "67a24e49-280f-4445-9fb4-821be36581ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test F1 Accuracy:  0.5692883895131086\n",
            "Test Flat Accuracy:  0.2261904761904762 \n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "Self-direction: action       0.60      0.55      0.57        11\n",
            "           Achievement       0.68      0.67      0.68        39\n",
            "    Security: personal       0.47      0.70      0.56        30\n",
            "    Security: societal       1.00      0.26      0.41        31\n",
            "   Benevolence: caring       0.60      0.50      0.55        12\n",
            " Universalism: concern       0.75      0.43      0.55        21\n",
            "\n",
            "             micro avg       0.62      0.53      0.57       144\n",
            "             macro avg       0.68      0.52      0.55       144\n",
            "          weighted avg       0.70      0.53      0.56       144\n",
            "           samples avg       0.60      0.56      0.54       144\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Print and save classification report\n",
        "\n",
        "print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n",
        "print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n",
        "clf_report = classification_report(true_bools,pred_bools,target_names=label_cols)\n",
        "pickle.dump(clf_report, open('classification_report.txt','wb')) #save report\n",
        "print(clf_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2iC9udBPEKf"
      },
      "source": [
        "#Optimization of the threshold "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnuw-g0snjud"
      },
      "source": [
        "The optimization of threshold is made by searching for the best results in terms of f1-macro and f1-micro score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQgCPDitO-Wo",
        "outputId": "26cec71f-750b-444f-c4e6-dfc94d7a78d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Threshold:  0.44\n",
            "Test F1 Accuracy:  0.5918367346938774\n",
            "Test Flat Accuracy:  0.2261904761904762 \n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "Self-direction: action       0.53      0.73      0.62        11\n",
            "           Achievement       0.67      0.74      0.71        39\n",
            "    Security: personal       0.44      0.77      0.56        30\n",
            "    Security: societal       0.91      0.32      0.48        31\n",
            "   Benevolence: caring       0.44      0.58      0.50        12\n",
            " Universalism: concern       0.77      0.48      0.59        21\n",
            "\n",
            "             micro avg       0.58      0.60      0.59       144\n",
            "             macro avg       0.63      0.60      0.57       144\n",
            "          weighted avg       0.66      0.60      0.59       144\n",
            "           samples avg       0.60      0.63      0.58       144\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "macro_thresholds = np.array(range(1,10))/10\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in macro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n",
        "\n",
        "micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n",
        "\n",
        "f1_results, flat_acc_results = [], []\n",
        "for th in micro_thresholds:\n",
        "  pred_bools = [pl>th for pl in pred_labels]\n",
        "  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n",
        "  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n",
        "  f1_results.append(test_f1_accuracy)\n",
        "  flat_acc_results.append(test_flat_accuracy)\n",
        "\n",
        "best_f1_idx = np.argmax(f1_results) #best threshold value\n",
        "\n",
        "\n",
        "best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n",
        "clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n",
        "pickle.dump(clf_report_optimized, open('classification_report_optimized.txt','wb'))\n",
        "print(clf_report_optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0H0Tt1VCo4F"
      },
      "source": [
        "reference:  https://towardsdatascience.com/transformers-for-multilabel-classification-71a1a0daf5e1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
